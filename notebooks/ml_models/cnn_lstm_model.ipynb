{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ad8e54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d309014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Reikalingos bibliotekos ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print(f\"TensorFlow versija: {tf.__version__}\")\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Duomenų gavimas iš Binance API (jei reikia) arba naudojami jau išsaugoti ---\n",
    "cached_data_path = os.path.join('..', '..', 'data', 'btc_data_1y_15m.csv')\n",
    "\n",
    "if os.path.exists(cached_data_path):\n",
    "    print(f\"Naudojami cached duomenys iš {cached_data_path}\")\n",
    "    df = pd.read_csv(cached_data_path)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    print(f\"Duomenų dydis: {df.shape}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"KLAIDA: Nerastas duomenų failas {cached_data_path}\")\n",
    "    print(\"Pirma paleiskite duomenų gavimo skriptą arba kitą modelio failą, pvz., lstm_model.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Duomenų paruošimas ir normalizavimas ---\n",
    "df = df.sort_values('time')\n",
    "columns_to_normalize = ['open', 'high', 'low', 'close', 'volume']\n",
    "scaler = MinMaxScaler()\n",
    "df_original = df.copy()\n",
    "df_normalized = df.copy()\n",
    "df_normalized[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "# Patikriname normalizuotus duomenis\n",
    "print(\"Normalizuotų duomenų statistika:\")\n",
    "print(df_normalized[columns_to_normalize].describe())\n",
    "\n",
    "# Išsaugome scaler'į vėlesniam naudojimui\n",
    "import pickle\n",
    "os.makedirs('../../models', exist_ok=True)\n",
    "with open('../../models/cnn_lstm_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Sliding window sekų kūrimas ---\n",
    "def create_sequences(data, target_column, sequence_length):\n",
    "    X, y = [], []\n",
    "    feature_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "    data_array = data[feature_columns].values\n",
    "    target_idx = feature_columns.index(target_column)\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data_array[i:i + sequence_length])\n",
    "        y.append(data_array[i + sequence_length, target_idx])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 48  # Hibridiniam modeliui pasirenkame vidutinio ilgio seką\n",
    "target_column = 'close'\n",
    "feature_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "X, y = create_sequences(df_normalized, target_column, sequence_length)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc894535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Duomenų padalijimas į mokymo ir testavimo rinkinius ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. CNN-LSTM hibridinio modelio sukūrimas ---\n",
    "def create_cnn_lstm_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        # 1D konvoliucijos sluoksnis lokalių šablonų aptikimui\n",
    "        layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # LSTM sluoksniai laiko eilučių priklausomybių modeliavimui\n",
    "        layers.LSTM(units=100, return_sequences=True),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.LSTM(units=50),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Tankinimo sluoksniai\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(25, activation='relu'),\n",
    "        layers.Dense(1)  # Išvesties sluoksnis (kainų prognozė)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Sukuriame modelį\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (sequence_length, features)\n",
    "cnn_lstm_model = create_cnn_lstm_model(input_shape)\n",
    "\n",
    "# Sukompiliuojame modelį\n",
    "cnn_lstm_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Modelio apmokymas ---\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath='../../models/cnn_lstm_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Apmokymo paleidimas\n",
    "print(\"Pradedamas modelio apmokymas...\")\n",
    "history = cnn_lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Modelio apmokymas baigtas.\")\n",
    "\n",
    "# Išsaugome modelį\n",
    "cnn_lstm_model.save('../../models/cnn_lstm_model.h5')\n",
    "print(\"Modelis išsaugotas į: ../../models/cnn_lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71900f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Apmokymo istorijos vizualizacija ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Mokymo klaida')\n",
    "plt.plot(history.history['val_loss'], label='Validavimo klaida')\n",
    "plt.title('CNN-LSTM modelio apmokymo istorija')\n",
    "plt.xlabel('Epocha')\n",
    "plt.ylabel('Klaida (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "if 'lr' in history.history:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['lr'])\n",
    "    plt.title('Learning Rate Kitimas')\n",
    "    plt.xlabel('Epocha')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Modelio testavimas ---\n",
    "y_pred = cnn_lstm_model.predict(X_test)\n",
    "\n",
    "def inverse_transform_predictions(predictions, scaler, target_idx=3, feature_names=None):\n",
    "    dummy = np.zeros((len(predictions), len(feature_names) if feature_names else 5))\n",
    "    dummy[:, target_idx] = predictions.flatten()\n",
    "    inverse_predicted = scaler.inverse_transform(dummy)\n",
    "    return inverse_predicted[:, target_idx]\n",
    "\n",
    "target_idx = feature_columns.index(target_column)\n",
    "y_pred_original = inverse_transform_predictions(y_pred, scaler, target_idx, feature_columns)\n",
    "y_test_original = inverse_transform_predictions(y_test.reshape(-1, 1), scaler, target_idx, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5bcc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Modelio įvertinimas ---\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "r2 = r2_score(y_test_original, y_pred_original)\n",
    "mape = np.mean(np.abs((y_test_original - y_pred_original) / y_test_original)) * 100\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Sukuriame DataFrame geresniam pavaizavimui\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metrika': ['MSE', 'RMSE', 'MAE', 'R²', 'MAPE (%)'],\n",
    "    'Reikšmė': [mse, rmse, mae, r2, mape]\n",
    "})\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. Prognozių vizualizacija ---\n",
    "# Pasiimame testavimo rinkinių datas\n",
    "test_dates = df_original['time'].iloc[-len(y_test):].reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_dates, y_test_original, label='Faktinė kaina', color='blue')\n",
    "plt.plot(test_dates, y_pred_original, label='CNN-LSTM prognozė', color='green', linestyle='--')\n",
    "plt.title('Bitcoin kainos prognozė (CNN-LSTM) vs Faktinė kaina')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Kaina (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 12. Modelio informacijos išsaugojimas ---\n",
    "model_info = {\n",
    "    'model_type': 'CNN-LSTM',\n",
    "    'input_shape': [sequence_length, len(feature_columns)],\n",
    "    'sequence_length': sequence_length,\n",
    "    'target_column': target_column,\n",
    "    'metrics': {\n",
    "        'mse': float(mse),\n",
    "        'rmse': float(rmse),\n",
    "        'mae': float(mae),\n",
    "        'r2': float(r2),\n",
    "        'mape': float(mape)\n",
    "    }\n",
    "}\n",
    "\n",
    "model_info_path = '../../models/cnn_lstm_model_info.json'\n",
    "with open(model_info_path, 'w') as f:\n",
    "    json.dump(model_info, f, indent=4)\n",
    "\n",
    "print(f\"Modelio informacija išsaugota: {model_info_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
