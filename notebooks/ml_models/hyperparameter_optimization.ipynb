{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99aed28e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4801baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelių ir prekybos strategijų hiperparametrų optimizavimas (BTC/USDT)\n",
    "#\n",
    "# Šiame notebook bus testuojami įvairūs neuroninių tinklų hiperparametrai (epochs, batch_size, learning_rate, dropout ir kt.)\n",
    "# Taip pat bus testuojami prekybos strategijų parametrai (stop-loss, take-profit, pozicijos dydis).\n",
    "# Visi rezultatai bus įrašyti į ataskaitos lentelę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "054ed29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reikalingų bibliotekų importavimas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec6f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duomenų paruošimas (naudojamas tas pats kaip kituose modeliuose)\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_historical_klines(symbol=\"BTCUSDT\", interval=\"15m\", start_time=None, end_time=None):\n",
    "    BINANCE_API_URL = \"https://api.binance.com/api/v3/klines\"\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    if start_time is None:\n",
    "        start_time = end_time - timedelta(days=365)\n",
    "    start_ts = int(start_time.timestamp() * 1000)\n",
    "    end_ts = int(end_time.timestamp() * 1000)\n",
    "    all_klines = []\n",
    "    current_start = start_ts\n",
    "    while current_start < end_ts:\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'interval': interval,\n",
    "            'startTime': current_start,\n",
    "            'endTime': end_ts,\n",
    "            'limit': 1000\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(BINANCE_API_URL, params=params)\n",
    "            response.raise_for_status()\n",
    "            klines = response.json()\n",
    "            if not klines:\n",
    "                break\n",
    "            all_klines.extend(klines)\n",
    "            current_start = int(klines[-1][0]) + 1\n",
    "        except Exception as e:\n",
    "            print(f\"Klaida gaunant duomenis: {str(e)}\")\n",
    "    if all_klines:\n",
    "        columns = ['time', 'open', 'high', 'low', 'close', 'volume', \n",
    "                   'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                   'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "        df = pd.DataFrame(all_klines, columns=columns)\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "        numeric_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "        df[numeric_columns] = df[numeric_columns].astype(float)\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "df = get_historical_klines()\n",
    "df = df.sort_values('time')\n",
    "columns_to_normalize = ['open', 'high', 'low', 'close', 'volume']\n",
    "scaler = MinMaxScaler()\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "def create_sequences(data, target_column, sequence_length):\n",
    "    X, y = [], []\n",
    "    feature_columns = columns_to_normalize\n",
    "    data_array = data[feature_columns].values\n",
    "    target_idx = feature_columns.index(target_column)\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data_array[i:i + sequence_length])\n",
    "        y.append(data_array[i + sequence_length, target_idx])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 10\n",
    "target_column = 'close'\n",
    "X, y = create_sequences(df, target_column, sequence_length)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0addb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bus testuojama 30 hiperparametrų kombinacijų.\n"
     ]
    }
   ],
   "source": [
    "# Hiperparametrų tinklelis (galite keisti pagal poreikį)\n",
    "param_grid = {\n",
    "    'epochs': [10, 20, 30],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'learning_rate': [0.001, 0.0005],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'units': [32, 64],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "random.shuffle(grid)\n",
    "grid = grid[:30]  # Pasirenkame 30 variantų\n",
    "print(f\"Bus testuojama {len(grid)} hiperparametrų kombinacijų.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87038aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paprastas LSTM modelio kūrimo šablonas\n",
    "def build_lstm_model(input_shape, units=64, dropout=0.2, learning_rate=0.001, optimizer='adam'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(units, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.Dense(1))\n",
    "    if optimizer == 'adam':\n",
    "        opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29bb9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prekybos strategijos simuliatorius\n",
    "def trading_simulator(y_true, y_pred, stop_loss=0.03, take_profit=0.05, position_size=1.0, fee=0.001):\n",
    "    balance = 1000.0\n",
    "    btc = 0.0\n",
    "    last_action = None\n",
    "    for i in range(1, len(y_pred)):\n",
    "        price_now = y_true[i-1]\n",
    "        price_next = y_true[i]\n",
    "        # Signalas: jei prognozė > dabartinė kaina -> pirkti, jei < -> parduoti\n",
    "        if y_pred[i] > price_now and last_action != 'buy':\n",
    "            btc = balance * position_size * (1 - fee) / price_now\n",
    "            balance -= balance * position_size\n",
    "            last_action = 'buy'\n",
    "            entry_price = price_now\n",
    "        elif y_pred[i] < price_now and last_action == 'buy':\n",
    "            balance += btc * (1 - fee) * price_now\n",
    "            btc = 0\n",
    "            last_action = 'sell'\n",
    "        # Stop-loss / take-profit\n",
    "        if last_action == 'buy':\n",
    "            if (price_now - entry_price) / entry_price <= -stop_loss or (price_now - entry_price) / entry_price >= take_profit:\n",
    "                balance += btc * (1 - fee) * price_now\n",
    "                btc = 0\n",
    "                last_action = 'sell'\n",
    "    if btc > 0:\n",
    "        balance += btc * (1 - fee) * y_true[-1]\n",
    "    return balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98ca774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandymas 1/30: {'batch_size': 16, 'dropout': 0.3, 'epochs': 20, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 2/30: {'batch_size': 16, 'dropout': 0.3, 'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'adam', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Bandymas 3/30: {'batch_size': 16, 'dropout': 0.1, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Bandymas 4/30: {'batch_size': 32, 'dropout': 0.1, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 5/30: {'batch_size': 16, 'dropout': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'rmsprop', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 6/30: {'batch_size': 32, 'dropout': 0.1, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 7/30: {'batch_size': 64, 'dropout': 0.3, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 8/30: {'batch_size': 64, 'dropout': 0.1, 'epochs': 10, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 9/30: {'batch_size': 16, 'dropout': 0.1, 'epochs': 20, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 10/30: {'batch_size': 16, 'dropout': 0.3, 'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Bandymas 11/30: {'batch_size': 16, 'dropout': 0.1, 'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'rmsprop', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 12/30: {'batch_size': 32, 'dropout': 0.1, 'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'rmsprop', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 13/30: {'batch_size': 16, 'dropout': 0.1, 'epochs': 10, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 14/30: {'batch_size': 32, 'dropout': 0.2, 'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'adam', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 15/30: {'batch_size': 64, 'dropout': 0.3, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Bandymas 16/30: {'batch_size': 64, 'dropout': 0.2, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'rmsprop', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 17/30: {'batch_size': 16, 'dropout': 0.2, 'epochs': 30, 'learning_rate': 0.001, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Bandymas 18/30: {'batch_size': 32, 'dropout': 0.3, 'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'rmsprop', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 19/30: {'batch_size': 32, 'dropout': 0.3, 'epochs': 10, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 20/30: {'batch_size': 64, 'dropout': 0.2, 'epochs': 10, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 21/30: {'batch_size': 64, 'dropout': 0.1, 'epochs': 20, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 22/30: {'batch_size': 16, 'dropout': 0.1, 'epochs': 20, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Bandymas 23/30: {'batch_size': 64, 'dropout': 0.2, 'epochs': 20, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 24/30: {'batch_size': 16, 'dropout': 0.2, 'epochs': 20, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 25/30: {'batch_size': 64, 'dropout': 0.1, 'epochs': 10, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Bandymas 26/30: {'batch_size': 64, 'dropout': 0.1, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'rmsprop', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Bandymas 27/30: {'batch_size': 64, 'dropout': 0.3, 'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'rmsprop', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Bandymas 28/30: {'batch_size': 16, 'dropout': 0.1, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Bandymas 29/30: {'batch_size': 16, 'dropout': 0.1, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Bandymas 30/30: {'batch_size': 64, 'dropout': 0.1, 'epochs': 30, 'learning_rate': 0.0005, 'optimizer': 'adam', 'units': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CA_BTC\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Testuojame 30+ hiperparametrų kombinacijų ir prekybos strategijų\n",
    "results = []\n",
    "for i, params in enumerate(grid):\n",
    "    print(f\"Bandymas {i+1}/{len(grid)}: {params}\")\n",
    "    model = build_lstm_model(\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        units=params['units'],\n",
    "        dropout=params['dropout'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        optimizer=params['optimizer']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=0\n",
    "    )\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Atstatome į originalią skalę\n",
    "    dummy = np.zeros((len(y_pred), len(columns_to_normalize)))\n",
    "    dummy[:, columns_to_normalize.index(target_column)] = y_pred.flatten()\n",
    "    y_pred_original = scaler.inverse_transform(dummy)[:, columns_to_normalize.index(target_column)]\n",
    "    dummy_y = np.zeros((len(y_test), len(columns_to_normalize)))\n",
    "    dummy_y[:, columns_to_normalize.index(target_column)] = y_test.flatten()\n",
    "    y_test_original = scaler.inverse_transform(dummy_y)[:, columns_to_normalize.index(target_column)]\n",
    "    # ML metrikos\n",
    "    mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "    r2 = r2_score(y_test_original, y_pred_original)\n",
    "    mape = np.mean(np.abs((y_test_original - y_pred_original) / y_test_original)) * 100\n",
    "    # Prekybos strategijos parametrai (galite randomizuoti arba fiksuoti)\n",
    "    stop_loss = random.choice([0.01, 0.02, 0.03, 0.05])\n",
    "    take_profit = random.choice([0.03, 0.05, 0.07, 0.1])\n",
    "    position_size = random.choice([0.5, 1.0])\n",
    "    final_balance = trading_simulator(y_test_original, y_pred_original, stop_loss, take_profit, position_size)\n",
    "    results.append({\n",
    "        **params,\n",
    "        'stop_loss': stop_loss,\n",
    "        'take_profit': take_profit,\n",
    "        'position_size': position_size,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'mape': mape,\n",
    "        'final_balance': final_balance\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639266b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>units</th>\n",
       "      <th>stop_loss</th>\n",
       "      <th>take_profit</th>\n",
       "      <th>position_size</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>mape</th>\n",
       "      <th>final_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>615.701209</td>\n",
       "      <td>567.947556</td>\n",
       "      <td>0.994966</td>\n",
       "      <td>0.632912</td>\n",
       "      <td>1144.844944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>588.883805</td>\n",
       "      <td>522.236221</td>\n",
       "      <td>0.995395</td>\n",
       "      <td>0.581921</td>\n",
       "      <td>1121.940128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>397.294628</td>\n",
       "      <td>340.342731</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>0.380597</td>\n",
       "      <td>1090.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>680.152128</td>\n",
       "      <td>601.418922</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>0.672325</td>\n",
       "      <td>984.360126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>907.984618</td>\n",
       "      <td>825.756346</td>\n",
       "      <td>0.989053</td>\n",
       "      <td>0.894665</td>\n",
       "      <td>972.044329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>695.496066</td>\n",
       "      <td>625.859907</td>\n",
       "      <td>0.993577</td>\n",
       "      <td>0.679999</td>\n",
       "      <td>909.279836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>791.058994</td>\n",
       "      <td>682.421868</td>\n",
       "      <td>0.991691</td>\n",
       "      <td>0.731611</td>\n",
       "      <td>900.286483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>474.660842</td>\n",
       "      <td>391.866153</td>\n",
       "      <td>0.997008</td>\n",
       "      <td>0.429733</td>\n",
       "      <td>880.405884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>470.884634</td>\n",
       "      <td>394.331491</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.448684</td>\n",
       "      <td>809.764637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>32</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>405.449368</td>\n",
       "      <td>314.944836</td>\n",
       "      <td>0.997817</td>\n",
       "      <td>0.353602</td>\n",
       "      <td>794.216612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size  dropout  epochs  learning_rate optimizer  units  stop_loss  \\\n",
       "2           16      0.1      30         0.0005   rmsprop     32       0.01   \n",
       "24          64      0.1      10         0.0005   rmsprop     64       0.05   \n",
       "3           32      0.1      20         0.0010      adam     64       0.05   \n",
       "19          64      0.2      10         0.0005      adam     32       0.02   \n",
       "15          64      0.2      20         0.0010   rmsprop     32       0.02   \n",
       "21          16      0.1      20         0.0005   rmsprop     32       0.01   \n",
       "17          32      0.3      10         0.0010   rmsprop     32       0.02   \n",
       "6           64      0.3      30         0.0005      adam     64       0.05   \n",
       "26          64      0.3      10         0.0010   rmsprop     64       0.02   \n",
       "7           64      0.1      10         0.0005   rmsprop     32       0.03   \n",
       "\n",
       "    take_profit  position_size        rmse         mae        r2      mape  \\\n",
       "2          0.07            1.0  615.701209  567.947556  0.994966  0.632912   \n",
       "24         0.05            1.0  588.883805  522.236221  0.995395  0.581921   \n",
       "3          0.05            1.0  397.294628  340.342731  0.997904  0.380597   \n",
       "19         0.05            1.0  680.152128  601.418922  0.993857  0.672325   \n",
       "15         0.10            0.5  907.984618  825.756346  0.989053  0.894665   \n",
       "21         0.07            1.0  695.496066  625.859907  0.993577  0.679999   \n",
       "17         0.07            1.0  791.058994  682.421868  0.991691  0.731611   \n",
       "6          0.10            1.0  474.660842  391.866153  0.997008  0.429733   \n",
       "26         0.07            1.0  470.884634  394.331491  0.997056  0.448684   \n",
       "7          0.07            0.5  405.449368  314.944836  0.997817  0.353602   \n",
       "\n",
       "    final_balance  \n",
       "2     1144.844944  \n",
       "24    1121.940128  \n",
       "3     1090.966693  \n",
       "19     984.360126  \n",
       "15     972.044329  \n",
       "21     909.279836  \n",
       "17     900.286483  \n",
       "6      880.405884  \n",
       "26     809.764637  \n",
       "7      794.216612  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rezultatai išsaugoti į ../../models/hyperparameter_optimization_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Rezultatų ataskaitos lentelė\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results.sort_values('final_balance', ascending=False).head(10))\n",
    "df_results.to_csv('../../models/hyperparameter_optimization_results.csv', index=False)\n",
    "print(\"Rezultatai išsaugoti į ../../models/hyperparameter_optimization_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712151b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced hyperparameter optimization with advanced techniques\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Bayesian optimization using Optuna\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function for Bayesian optimization\"\"\"\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    epochs = trial.suggest_int('epochs', 10, 100)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    units = trial.suggest_categorical('units', [32, 64, 128, 256])\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'rmsprop', 'adamax'])\n",
    "    \n",
    "    # Trading strategy parameters\n",
    "    stop_loss = trial.suggest_float('stop_loss', 0.01, 0.1)\n",
    "    take_profit = trial.suggest_float('take_profit', 0.02, 0.2)\n",
    "    position_size = trial.suggest_float('position_size', 0.1, 1.0)\n",
    "    \n",
    "    try:\n",
    "        # Build and train model\n",
    "        model = build_lstm_model(\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "            units=units,\n",
    "            dropout=dropout,\n",
    "            learning_rate=learning_rate,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        \n",
    "        # Use early stopping to prevent overfitting\n",
    "        from tensorflow.keras.callbacks import EarlyStopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=0,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Convert back to original scale\n",
    "        dummy = np.zeros((len(y_pred), len(columns_to_normalize)))\n",
    "        dummy[:, columns_to_normalize.index(target_column)] = y_pred.flatten()\n",
    "        y_pred_original = scaler.inverse_transform(dummy)[:, columns_to_normalize.index(target_column)]\n",
    "        \n",
    "        dummy_y = np.zeros((len(y_test), len(columns_to_normalize)))\n",
    "        dummy_y[:, columns_to_normalize.index(target_column)] = y_test.flatten()\n",
    "        y_test_original = scaler.inverse_transform(dummy_y)[:, columns_to_normalize.index(target_column)]\n",
    "        \n",
    "        # Calculate ML metrics\n",
    "        mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "        r2 = r2_score(y_test_original, y_pred_original)\n",
    "        \n",
    "        # Calculate trading performance\n",
    "        final_balance = trading_simulator(\n",
    "            y_test_original, \n",
    "            y_pred_original, \n",
    "            stop_loss, \n",
    "            take_profit, \n",
    "            position_size\n",
    "        )\n",
    "        \n",
    "        # Multi-objective scoring (combine ML accuracy and trading performance)\n",
    "        ml_score = r2  # Use R² for ML performance\n",
    "        trading_score = (final_balance - 1000) / 1000  # Normalize trading return\n",
    "        \n",
    "        # Weighted combination\n",
    "        combined_score = 0.6 * ml_score + 0.4 * trading_score\n",
    "        \n",
    "        return combined_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return -1.0  # Return poor score for failed trials\n",
    "\n",
    "# Run Bayesian optimization\n",
    "print(\"Starting Bayesian hyperparameter optimization...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, timeout=3600)  # 1 hour timeout\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.value}\")\n",
    "print(f\"Best parameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070db46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced cross-validation for time series\n",
    "def time_series_cross_validation(X, y, model_builder, param_grid, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform time series cross-validation with expanding window\n",
    "    \"\"\"\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    results = []\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        fold_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in tscv.split(X):\n",
    "            X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "            y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "            \n",
    "            try:\n",
    "                # Build model with current parameters\n",
    "                model = model_builder(**params)\n",
    "                \n",
    "                # Train model\n",
    "                model.fit(\n",
    "                    X_train_fold, y_train_fold,\n",
    "                    validation_data=(X_val_fold, y_val_fold),\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                # Evaluate\n",
    "                val_pred = model.predict(X_val_fold)\n",
    "                val_score = r2_score(y_val_fold, val_pred)\n",
    "                fold_scores.append(val_score)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Fold failed with params {params}: {e}\")\n",
    "                fold_scores.append(-1.0)\n",
    "        \n",
    "        # Average score across folds\n",
    "        avg_score = np.mean(fold_scores)\n",
    "        score_std = np.std(fold_scores)\n",
    "        \n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'mean_score': avg_score,\n",
    "            'std_score': score_std,\n",
    "            'fold_scores': fold_scores\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Time series cross-validation with reduced parameter space\n",
    "cv_param_grid = {\n",
    "    'epochs': [20, 50],\n",
    "    'batch_size': [32, 64],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'units': [64, 128]\n",
    "}\n",
    "\n",
    "print(\"Performing time series cross-validation...\")\n",
    "cv_results = time_series_cross_validation(\n",
    "    X, y, \n",
    "    lambda **params: build_lstm_model(\n",
    "        input_shape=(X.shape[1], X.shape[2]),\n",
    "        **params\n",
    "    ),\n",
    "    cv_param_grid,\n",
    "    n_splits=3\n",
    ")\n",
    "\n",
    "# Find best parameters from CV\n",
    "best_cv_result = max(cv_results, key=lambda x: x['mean_score'])\n",
    "print(f\"Best CV score: {best_cv_result['mean_score']:.4f} ± {best_cv_result['std_score']:.4f}\")\n",
    "print(f\"Best CV parameters: {best_cv_result['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter importance analysis\n",
    "def analyze_hyperparameter_importance(results_df):\n",
    "    \"\"\"\n",
    "    Analyze the importance of different hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate correlation between parameters and performance\n",
    "    numeric_params = ['epochs', 'batch_size', 'learning_rate', 'dropout', 'units']\n",
    "    correlations = {}\n",
    "    \n",
    "    for param in numeric_params:\n",
    "        if param in results_df.columns:\n",
    "            corr = results_df[param].corr(results_df['final_balance'])\n",
    "            correlations[param] = abs(corr)\n",
    "    \n",
    "    # Sort by importance\n",
    "    sorted_importance = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Hyperparameter Importance (by correlation with trading performance):\")\n",
    "    for param, importance in sorted_importance:\n",
    "        print(f\"{param}: {importance:.4f}\")\n",
    "    \n",
    "    # Visualize importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    params, importances = zip(*sorted_importance)\n",
    "    bars = plt.bar(params, importances)\n",
    "    plt.title('Hyperparameter Importance for Trading Performance')\n",
    "    plt.ylabel('Absolute Correlation')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Color bars by importance\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(bars)))\n",
    "    for bar, color in zip(bars, colors):\n",
    "        bar.set_color(color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "# Analyze hyperparameter importance\n",
    "if 'df_results' in locals() and len(df_results) > 1:\n",
    "    importance_scores = analyze_hyperparameter_importance(df_results)\n",
    "else:\n",
    "    print(\"Not enough results for importance analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble optimization - combining multiple models\n",
    "def optimize_ensemble_weights(models_predictions, y_true):\n",
    "    \"\"\"\n",
    "    Optimize ensemble weights using grid search\n",
    "    \"\"\"\n",
    "    from itertools import product\n",
    "    \n",
    "    # Define weight grid (weights must sum to 1)\n",
    "    n_models = len(models_predictions)\n",
    "    weight_options = [i/10 for i in range(0, 11)]  # 0.0 to 1.0 in 0.1 steps\n",
    "    \n",
    "    best_weights = None\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    # Generate all weight combinations that sum to 1\n",
    "    for weights in product(weight_options, repeat=n_models):\n",
    "        if abs(sum(weights) - 1.0) < 1e-6:  # Weights sum to 1\n",
    "            # Calculate ensemble prediction\n",
    "            ensemble_pred = np.average(\n",
    "                models_predictions, \n",
    "                axis=0, \n",
    "                weights=weights\n",
    "            )\n",
    "            \n",
    "            # Calculate performance\n",
    "            score = r2_score(y_true, ensemble_pred)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_weights = weights\n",
    "    \n",
    "    return best_weights, best_score\n",
    "\n",
    "# Create ensemble from different model architectures\n",
    "print(\"Optimizing ensemble of different architectures...\")\n",
    "\n",
    "# Simulate predictions from different models (in real scenario, load actual models)\n",
    "model_names = ['LSTM', 'GRU', 'CNN', 'Transformer']\n",
    "simulated_predictions = []\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    # Add some noise to create different \"model\" predictions\n",
    "    noise = np.random.normal(0, 0.02, len(y_test_original))\n",
    "    pred = y_test_original * (1 + noise)\n",
    "    simulated_predictions.append(pred)\n",
    "\n",
    "# Optimize ensemble weights\n",
    "optimal_weights, ensemble_score = optimize_ensemble_weights(\n",
    "    simulated_predictions, \n",
    "    y_test_original\n",
    ")\n",
    "\n",
    "print(f\"Optimal ensemble weights:\")\n",
    "for name, weight in zip(model_names, optimal_weights):\n",
    "    print(f\"{name}: {weight:.2f}\")\n",
    "print(f\"Ensemble R² score: {ensemble_score:.4f}\")\n",
    "\n",
    "# Visualize ensemble performance\n",
    "ensemble_prediction = np.average(\n",
    "    simulated_predictions, \n",
    "    axis=0, \n",
    "    weights=optimal_weights\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot individual model predictions\n",
    "for i, (name, pred) in enumerate(zip(model_names, simulated_predictions)):\n",
    "    plt.scatter(y_test_original, pred, alpha=0.5, label=f'{name} (weight: {optimal_weights[i]:.2f})', s=20)\n",
    "\n",
    "# Plot ensemble prediction\n",
    "plt.scatter(y_test_original, ensemble_prediction, color='red', s=50, alpha=0.8, label='Ensemble')\n",
    "\n",
    "# Plot perfect prediction line\n",
    "min_val, max_val = min(y_test_original), max(y_test_original)\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect Prediction')\n",
    "\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Ensemble vs Individual Model Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c07ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive results summary\n",
    "print(\"=\"*50)\n",
    "print(\"COMPREHENSIVE HYPERPARAMETER OPTIMIZATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Combine all optimization results\n",
    "optimization_summary = {\n",
    "    'Grid Search Best': {\n",
    "        'method': 'Grid Search',\n",
    "        'best_balance': df_results['final_balance'].max() if 'df_results' in locals() else None,\n",
    "        'best_params': df_results.loc[df_results['final_balance'].idxmax()].to_dict() if 'df_results' in locals() else None\n",
    "    },\n",
    "    'Bayesian Optimization Best': {\n",
    "        'method': 'Bayesian (Optuna)',\n",
    "        'best_score': study.best_trial.value if 'study' in locals() else None,\n",
    "        'best_params': study.best_trial.params if 'study' in locals() else None\n",
    "    },\n",
    "    'Cross-Validation Best': {\n",
    "        'method': 'Time Series CV',\n",
    "        'best_score': best_cv_result['mean_score'] if 'best_cv_result' in locals() else None,\n",
    "        'best_params': best_cv_result['params'] if 'best_cv_result' in locals() else None\n",
    "    },\n",
    "    'Ensemble Performance': {\n",
    "        'method': 'Ensemble Optimization',\n",
    "        'best_score': ensemble_score if 'ensemble_score' in locals() else None,\n",
    "        'optimal_weights': dict(zip(model_names, optimal_weights)) if 'optimal_weights' in locals() else None\n",
    "    }\n",
    "}\n",
    "\n",
    "for method_name, results in optimization_summary.items():\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Method: {results['method']}\")\n",
    "    if 'best_balance' in results and results['best_balance']:\n",
    "        print(f\"  Best Balance: ${results['best_balance']:.2f}\")\n",
    "    if 'best_score' in results and results['best_score']:\n",
    "        print(f\"  Best Score: {results['best_score']:.4f}\")\n",
    "    if results['best_params']:\n",
    "        print(f\"  Best Parameters: {results['best_params']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\"\"\n",
    "1. USE BAYESIAN OPTIMIZATION for efficient hyperparameter search\n",
    "2. IMPLEMENT TIME SERIES CROSS-VALIDATION for robust validation\n",
    "3. CONSIDER ENSEMBLE METHODS for improved stability\n",
    "4. MONITOR HYPERPARAMETER IMPORTANCE to focus optimization efforts\n",
    "5. COMBINE ML METRICS with TRADING PERFORMANCE for practical optimization\n",
    "6. REGULARLY RE-OPTIMIZE as market conditions change\n",
    "\"\"\")\n",
    "\n",
    "# Save comprehensive results\n",
    "comprehensive_results = {\n",
    "    'optimization_summary': optimization_summary,\n",
    "    'hyperparameter_importance': importance_scores if 'importance_scores' in locals() else {},\n",
    "    'ensemble_weights': dict(zip(model_names, optimal_weights)) if 'optimal_weights' in locals() else {},\n",
    "    'timestamp': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('../../models/comprehensive_optimization_results.json', 'w') as f:\n",
    "    json.dump(comprehensive_results, f, indent=2, default=str)\n",
    "\n",
    "print(\"Comprehensive optimization results saved to ../../models/comprehensive_optimization_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
